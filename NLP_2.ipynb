{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMauSJp/MygUmZzp6G9xtq7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Czwl_Ql7VgXB",
        "outputId": "8d949d7d-cbc2-4276-948f-25f434b673d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Style text summarized to 400 tokens.\n",
            "Input text summarized to 344 tokens.\n",
            "Query generated and saved.\n",
            "\n",
            "Input Summary Preview:\n",
            " Cognitive Behavioral Therapy\n",
            "\n",
            "Cognitive behavioral therapy (CBT) is a psycho-social intervention that aims to improve mental health. CBT focuses on challenging and changing unhelpful cognitive distortions and behaviors, improving emotional regulation, and developing personal coping strategies that target solving current problems.\n",
            "\n",
            "Originally developed to treat depression, CBT is now used for a variety of mental health conditions, including anxiety disorders, alcohol and drug use problems, marital problems, eating disorders, and severe mental illness. It is typically short-term and goal-oriented, involving collaboration between therapist and client.\n",
            "\n",
            "CBT is based on the concept that your thoughts, feelings, and actions are interconnected, and that negative thoughts and feelings can trap you in a vicious cycle. It helps you deal with overwhelming problems in a more positive way by breaking them down into smaller parts.\n",
            "\n",
            "A key part of CBT is helping patients identify and challenge distort\n",
            "\n",
            "Style Summary Preview:\n",
            " The Psychology of Habits\n",
            "\n",
            "We all want to make changes in our lives. The problem is not desire; the problem is consistency. You may want to exercise more, eat healthier, or learn a new skill, but how do you make those habits stick?\n",
            "\n",
            "Habits are the small decisions you make and actions you perform every day. According to researchers at Duke University, habits account for about 40% of our behaviors on any given day. Your life today is essentially the sum of your habits.\n",
            "\n",
            "The process of building a habit can be divided into four simple steps: cue, craving, response, and reward. This is the habit loop. Every habit starts with a cue — a trigger that initiates behavior. Then comes the craving, the motivational force. This leads to a response — the actual habit you perform. Finally, there is a reward — the benefit you gain from doing the behavior.\n",
            "\n",
            "Let’s take an example: You walk into a dark room (cue), you crave to see (craving), you flip the light switch (response), and the room is illuminated\n",
            "\n",
            "Query Preview:\n",
            " Input Text Summary:\n",
            "Cognitive Behavioral Therapy\n",
            "\n",
            "Cognitive behavioral therapy (CBT) is a psycho-social intervention that aims to improve mental health. CBT focuses on challenging and changing unhelpful cognitive distortions and behaviors, improving emotional regulation, and developing personal coping strategies that target solving current problems.\n",
            "\n",
            "Originally developed to treat depression, CBT is now used for a variety of mental health conditions, including anxiety disorders, alcohol and drug use problems, marital problems, eating disorders, and severe mental illness. It is typically short-term and goal-oriented, involving collaboration between therapist and client.\n",
            "\n",
            "CBT is based on the concept that your thoughts, feelings, and actions are interconnected, and that negative thoughts and feelings can trap you in a vicious cycle. It helps you deal with overwhelming problems in a more positive way by breaking them down into smaller parts.\n",
            "\n",
            "A key part of CBT is helping patients identify a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from collections import defaultdict\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "class HierarchicalStyleSummarizer:\n",
        "    def __init__(self, context_window=4000):\n",
        "        self.context_window = context_window  # max tokens in a summary chunk\n",
        "\n",
        "    def get_frequency_distribution(self, text):\n",
        "        words = word_tokenize(text.lower())\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        return FreqDist(word for word in words if word.isalnum() and word not in stop_words)\n",
        "\n",
        "    def summarize_text(self, text, freq_dist):\n",
        "        \"\"\"\n",
        "        Summarize the given text chunk by scoring sentences on word freq.\n",
        "        No fixed target length, just return top sentences up to chunk token limit.\n",
        "        \"\"\"\n",
        "        sentences = sent_tokenize(text)\n",
        "        sentence_scores = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            score = sum(freq_dist.get(word.lower(), 0) for word in word_tokenize(sentence) if word.isalnum())\n",
        "            sentence_scores.append((score, sentence))\n",
        "\n",
        "        # Sort sentences by score descending\n",
        "        sentence_scores.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        # Add sentences until near the context window token limit\n",
        "        selected_sentences = []\n",
        "        current_tokens = 0\n",
        "\n",
        "        for score, sent in sentence_scores:\n",
        "            sent_tokens = len(word_tokenize(sent))\n",
        "            if current_tokens + sent_tokens <= self.context_window:\n",
        "                selected_sentences.append(sent)\n",
        "                current_tokens += sent_tokens\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        # Return detokenized summary\n",
        "        return TreebankWordDetokenizer().detokenize(selected_sentences)\n",
        "\n",
        "    def split_into_chunks(self, text, max_tokens):\n",
        "        sentences = sent_tokenize(text)\n",
        "        chunks = []\n",
        "        current_chunk = []\n",
        "        current_length = 0\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence_length = len(word_tokenize(sentence))\n",
        "            if current_length + sentence_length <= max_tokens:\n",
        "                current_chunk.append(sentence)\n",
        "                current_length += sentence_length\n",
        "            else:\n",
        "                chunks.append(' '.join(current_chunk))\n",
        "                current_chunk = [sentence]\n",
        "                current_length = sentence_length\n",
        "\n",
        "        if current_chunk:\n",
        "            chunks.append(' '.join(current_chunk))\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def hierarchical_summarization(self, text):\n",
        "        \"\"\"\n",
        "        Hierarchical summarization:\n",
        "        - Split text into chunks fitting context window\n",
        "        - Summarize each chunk (no explicit target size)\n",
        "        - Collate chunk summaries\n",
        "        - Repeat until summary fits context window\n",
        "        \"\"\"\n",
        "        current_text = text\n",
        "        iteration = 0\n",
        "\n",
        "        while True:\n",
        "            iteration += 1\n",
        "            token_count = len(word_tokenize(current_text))\n",
        "            if token_count <= self.context_window:\n",
        "                break  # summary fits context window\n",
        "\n",
        "            # Split into chunks\n",
        "            chunks = self.split_into_chunks(current_text, self.context_window)\n",
        "            freq_dist = self.get_frequency_distribution(current_text)\n",
        "\n",
        "            chunk_summaries = []\n",
        "            for chunk in chunks:\n",
        "                summary = self.summarize_text(chunk, freq_dist)\n",
        "                chunk_summaries.append(summary)\n",
        "\n",
        "            current_text = ' '.join(chunk_summaries)\n",
        "            # Safety check to avoid infinite loops\n",
        "            if iteration > 10:\n",
        "                print(\"Reached max iterations in hierarchical summarization.\")\n",
        "                break\n",
        "\n",
        "        return current_text\n",
        "\n",
        "    def compute_proportional_lengths(self, text1, text2):\n",
        "        len1 = len(word_tokenize(text1))\n",
        "        len2 = len(word_tokenize(text2))\n",
        "        total = len1 + len2\n",
        "        # Ensure no zero division\n",
        "        if total == 0:\n",
        "            return self.context_window // 2, self.context_window // 2\n",
        "        return int((len1 / total) * self.context_window), int((len2 / total) * self.context_window)\n",
        "\n",
        "    def save_document(self, text, filename):\n",
        "        with open(filename, 'w', encoding='utf-8') as f:\n",
        "            f.write(text)\n",
        "\n",
        "    def generate_query(self, input_summary, style_summary):\n",
        "        \"\"\"\n",
        "        Generate a query combining the two summaries and meta info.\n",
        "        For example, concatenating summaries with a note.\n",
        "        \"\"\"\n",
        "        query = (\n",
        "            \"Input Text Summary:\\n\"\n",
        "            + input_summary\n",
        "            + \"\\n\\nStyle Text Summary:\\n\"\n",
        "            + style_summary\n",
        "            + \"\\n\\n\"\n",
        "            + \"Please generate a summary of the input text following the style of the style text.\"\n",
        "        )\n",
        "        return query\n",
        "\n",
        "    def process_documents(self, input_file, style_file, output_input_summary, output_style_summary, output_query_file):\n",
        "        # Load texts\n",
        "        with open(input_file, 'r', encoding='utf-8') as f:\n",
        "            input_text = f.read()\n",
        "        with open(style_file, 'r', encoding='utf-8') as f:\n",
        "            style_text = f.read()\n",
        "\n",
        "        # Compute proportional target lengths (used for info, though chunk size is fixed)\n",
        "        target_input_len, target_style_len = self.compute_proportional_lengths(input_text, style_text)\n",
        "\n",
        "        # Summarize style text hierarchically\n",
        "        style_summary = self.hierarchical_summarization(style_text)\n",
        "        self.save_document(style_summary, output_style_summary)\n",
        "        print(f\"Style text summarized to {len(word_tokenize(style_summary))} tokens.\")\n",
        "\n",
        "        # Summarize input text hierarchically\n",
        "        input_summary = self.hierarchical_summarization(input_text)\n",
        "        self.save_document(input_summary, output_input_summary)\n",
        "        print(f\"Input text summarized to {len(word_tokenize(input_summary))} tokens.\")\n",
        "\n",
        "        # Generate and save query\n",
        "        query = self.generate_query(input_summary, style_summary)\n",
        "        self.save_document(query, output_query_file)\n",
        "        print(\"Query generated and saved.\")\n",
        "\n",
        "        return input_summary, style_summary, query\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    summarizer = HierarchicalStyleSummarizer(context_window=4000)\n",
        "\n",
        "    input_file = \"/content/input.txt\"\n",
        "    style_file = \"/content/style.txt\"\n",
        "    output_input_summary = \"/content/input_summary.txt\"\n",
        "    output_style_summary = \"/content/style_summary.txt\"\n",
        "    output_query_file = \"/content/final_query.txt\"\n",
        "\n",
        "    input_summary, style_summary, query = summarizer.process_documents(\n",
        "        input_file, style_file, output_input_summary, output_style_summary, output_query_file\n",
        "    )\n",
        "\n",
        "    print(\"\\nInput Summary Preview:\\n\", input_summary[:1000])\n",
        "    print(\"\\nStyle Summary Preview:\\n\", style_summary[:1000])\n",
        "    print(\"\\nQuery Preview:\\n\", query[:1000])\n"
      ]
    }
  ]
}